{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis with Prophet model\n",
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# modeling\n",
    "from prophet import Prophet\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from prophet.plot import plot_plotly, plot_components_plotly\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\"\n",
    "sns.axes_style(\"darkgrid\")\n",
    "sns.set_theme()\n",
    "\n",
    "# evaluating\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from prophet.diagnostics import performance_metrics\n",
    "\n",
    "# showing\n",
    "from IPython.display import display\n",
    "\n",
    "# model saving/loading\n",
    "from prophet.serialize import model_from_json, model_to_json\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import sys\n",
    "# adding to the path variables the one folder higher (locally, not changing system variables)\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import mlflow\n",
    "#from mlflow import prophet\n",
    "\n",
    "from modeling.config import EXPERIMENT_NAME\n",
    "TRACKING_URI = open(\"../.mlflow_uri\").read().strip()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from prophet.serialize import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train data and format timestamp column\n",
    "df = pd.read_csv('../data/cleaned_sensors_dwd_train.csv', index_col=0)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# import test data and format timestamp column\n",
    "df_test_data = pd.read_csv('../data/cleaned_sensors_dwd_test.csv', index_col=0)\n",
    "df_test_data['timestamp'] = pd.to_datetime(df_test_data['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose location and set prediction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose locations (all or several)\n",
    "#location_list_reg = df['location_id'].unique().tolist()\n",
    "# several: six locations chosen for hyperparameter tuning\n",
    "location_list_reg = [133, 159, 129, 14, 119, 52]\n",
    "#location_list_reg = [133]\n",
    "\n",
    "prediction_time = 7 * 24    # days * hours\n",
    "\n",
    "NUMBER_OF_MODELS_REG = len(location_list_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prophet with regressors\n",
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare DataFrame for prophet with column names as expected\n",
    "# regressors\n",
    "df_prophet_reg = df[['timestamp','PM2p5','location_id', 'humidity_dwd', 'temperature_dwd', 'pressure_dwd', 'wind_speed', 'precip', 'wind_direction', 'city']]  \n",
    "df_prophet_reg.rename(columns={'timestamp': 'ds', 'PM2p5': 'y', 'humidity_dwd': 'humi', 'temperature_dwd': 'temp', 'pressure_dwd': 'press', 'wind_speed': 'windsp', 'precip': 'precip', 'wind_direction': 'winddir'}, inplace=True) #\n",
    "\n",
    "# drop nans\n",
    "df_prophet_reg.dropna(subset=['humi', 'temp', 'press', 'windsp', 'precip', 'winddir'], inplace=True)\n",
    "\n",
    "#print(df_prophet_reg.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_regressor_column(ds, train_col, test_col):\n",
    "    \"\"\"Get a regressor of train or test data for corresponding timestamp (needed for creation of future_dataframe)\n",
    "\n",
    "    Args:\n",
    "        ds (datetime): timestamp\n",
    "        train_col (string): column name of regressor in train data\n",
    "        test_col (string): column name of regressor in test data\n",
    "\n",
    "    Returns:\n",
    "        float: regressor value for given timestamp\n",
    "    \"\"\"\n",
    "    \n",
    "    if ds in df_prophet_reg['ds'].values:\n",
    "        return df_prophet_reg[df_prophet_reg['ds'] == ds][train_col].values[0]\n",
    "    elif ds in df_test_data['timestamp'].values:\n",
    "        return df_test_data[df_test_data['timestamp'] == ds][test_col].values[0]\n",
    "    else:\n",
    "        return np.nan\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_convert(sec):\n",
    "  mins = sec // 60\n",
    "  sec = sec % 60\n",
    "  hours = mins // 60\n",
    "  mins = mins % 60\n",
    "\n",
    "  sec_str = ('0' + str(int(sec)))[-2:]\n",
    "  mins_str = ('0' + str(int(mins)))[-2:]\n",
    "  hours_str = ('0' + str(int(hours)))[-2:]  \n",
    "  #print(\"Time Lapsed = {0}:{1}:{2}\".format(int(hours),int(mins),sec))\n",
    "  return hours_str + ':' + mins_str + ':' + sec_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyperparameters\n",
    "# Edit to try out different settings\n",
    "run_name = 'test'\n",
    "\n",
    "seasonality_mode='additive'\n",
    "yearly_seasonality=True\n",
    "weekly_seasonality=True\n",
    "daily_seasonality=True\n",
    "\n",
    "growth='logistic'\n",
    "n_changepoints=20\n",
    "\n",
    "temp_flag = True\n",
    "humi_flag = True\n",
    "press_flag = True\n",
    "windsp_flag = True\n",
    "winddir_flag = True\n",
    "precip_flag = False\n",
    "\n",
    "temp_prior_scale = 1.00\n",
    "humi_prior_scale = 1.00\n",
    "press_prior_scale = 1.00\n",
    "windsp_prior_scale = 1.00\n",
    "winddir_prior_scale = 1.00\n",
    "precip_prior_scale = 1.00\n",
    "\n",
    "if not temp_flag:\n",
    "    temp_prior_scale = None\n",
    "if not humi_flag:\n",
    "    humi_prior_scale = None\n",
    "if not press_flag:\n",
    "    press_prior_scale = None\n",
    "if not windsp_flag:\n",
    "    windsp_prior_scale = None\n",
    "if not winddir_flag:\n",
    "    winddir_prior_scale = None\n",
    "if not precip_flag:\n",
    "    precip_prior_scale = None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary to save models later\n",
    "prophet_models_per_location_reg = {}\n",
    "\n",
    "# create dictionary to save prediction results\n",
    "prophet_forecasts_per_location_reg = {}\n",
    "\n",
    "# create dictionaries for RMSE of train and test data\n",
    "rmse_dict_reg_train = {}\n",
    "rmse_dict_reg_test = {}\n",
    "\n",
    "# train model for selected locations\n",
    "for n, location_id in enumerate(location_list_reg[:NUMBER_OF_MODELS_REG]):\n",
    "    print('-----'*10)\n",
    "    print(f'no: {n + 1}, location_id: {location_id}')\n",
    "    start_time = time.time()\n",
    "\n",
    "    # limit dataframe to specific location_id\n",
    "    df_location_reg = df_prophet_reg[df_prophet_reg['location_id'] == location_id]\n",
    "\n",
    "    # calculate cap and floor for growth = logistic\n",
    "    # calculate moving average of training\n",
    "    df_average = df_location_reg[['location_id', 'ds', 'y']]\n",
    "\n",
    "    \n",
    "    df_average['PM2p5_average'] = df_average['y'].rolling(window=5, center=True).mean()\n",
    "\n",
    "    # calculate cap and floor for all locations\n",
    "    cap = df_average[['PM2p5_average']].quantile(0.99)[0]\n",
    "    floor = df_average[['PM2p5_average']].min()[0]\n",
    "\n",
    "    # add cap and floor for growth=logistic\n",
    "    df_location_reg['cap'] = cap\n",
    "    df_location_reg['floor'] = floor\n",
    "\n",
    "    city = df_location_reg['city'].max()\n",
    "\n",
    "    # drop columns that are not needed\n",
    "    df_location_reg.drop(['location_id', 'city'], axis=1, inplace=True)\n",
    "\n",
    "    # init Prophet model and fit it to train data for given location\n",
    "    model_reg = Prophet(seasonality_mode=seasonality_mode, yearly_seasonality=yearly_seasonality, weekly_seasonality=weekly_seasonality,\n",
    "                     daily_seasonality=daily_seasonality, growth=growth,n_changepoints=n_changepoints)\n",
    "    # regressors\n",
    "    if temp_flag:\n",
    "        model_reg.add_regressor('temp', standardize=True, prior_scale=temp_prior_scale)\n",
    "    if humi_flag:\n",
    "        model_reg.add_regressor('humi', standardize=True, prior_scale=humi_prior_scale)\n",
    "    if press_flag:\n",
    "        model_reg.add_regressor('press', standardize=True, prior_scale=press_prior_scale)\n",
    "    if windsp_flag:\n",
    "        model_reg.add_regressor('windsp', standardize=True, prior_scale=windsp_prior_scale)\n",
    "    if winddir_flag:\n",
    "        model_reg.add_regressor('winddir', standardize=True, prior_scale=winddir_prior_scale)\n",
    "    if precip_flag:\n",
    "        model_reg.add_regressor('precip', standardize=True, prior_scale=precip_prior_scale)\n",
    "\n",
    "    print(f'start training')\n",
    "    model_reg.fit(df_location_reg)\n",
    "\n",
    "    # save model in dictionary\n",
    "    prophet_models_per_location_reg[location_id] = model_reg\n",
    "\n",
    "    #------------------------------------------------\n",
    "    print(f'start prediction')\n",
    "    print(f'')\n",
    "    # prediction\n",
    "    # limit test data to current location\n",
    "    df_test_location = df_test_data[df_test_data['location_id'] == location_id]\n",
    "\n",
    "    # create dataframe for future predictions and predict\n",
    "    future_reg = model_reg.make_future_dataframe(periods=prediction_time, freq='H')\n",
    "\n",
    "    if temp_flag:\n",
    "        future_reg['temp'] = future_reg['ds'].apply(create_regressor_column, args=('temp', 'temperature_dwd'))\n",
    "    if humi_flag:\n",
    "        future_reg['humi'] = future_reg['ds'].apply(create_regressor_column, args=('humi', 'humidity_dwd'))\n",
    "    if press_flag:\n",
    "        future_reg['press'] = future_reg['ds'].apply(create_regressor_column, args=('press', 'pressure_dwd'))\n",
    "    if windsp_flag:\n",
    "        future_reg['windsp'] = future_reg['ds'].apply(create_regressor_column, args=('windsp', 'wind_speed'))   \n",
    "    if winddir_flag:\n",
    "        future_reg['winddir'] = future_reg['ds'].apply(create_regressor_column, args=('winddir', 'wind_direction'))   \n",
    "    if precip_flag:\n",
    "        future_reg['precip'] = future_reg['ds'].apply(create_regressor_column, args=('precip', 'precip'))   \n",
    "\n",
    "    # drop nans\n",
    "    future_reg.dropna(inplace=True)\n",
    "    \n",
    "    # add cap and floor for growth = logistic\n",
    "    future_reg['cap'] = cap\n",
    "    future_reg['floor'] = floor\n",
    "\n",
    "    # predict for given location\n",
    "    forecast_reg = model_reg.predict(future_reg)\n",
    "\n",
    "    # save predictions in dataframe\n",
    "    prophet_forecasts_per_location_reg[location_id] = forecast_reg\n",
    "\n",
    "    #---------------------------------------\n",
    "    print(f'calculate rmse')\n",
    "    # Calculate Metrics\n",
    "    # test data\n",
    "    # limit columns of test data for calculating rmse and limit timespan to predicted timespan\n",
    "    df_rmse_test_reg = df_test_location.query(f\"timestamp <= '{max(forecast_reg.ds)}'\")[['timestamp','PM2p5']]\n",
    "    if len(df_rmse_test_reg) != 0:\n",
    "        # merge forecast to test data\n",
    "        df_rmse_test_reg = df_rmse_test_reg.merge(forecast_reg[['yhat', 'ds']], how='left', left_on='timestamp', right_on='ds').drop(columns='ds', axis=1)\n",
    "        # drop NaN        \n",
    "        df_rmse_test_reg.dropna(inplace=True)\n",
    "        # calculate rmse for specific time span\n",
    "        rmse_test_reg = mean_squared_error(df_rmse_test_reg['PM2p5'], df_rmse_test_reg['yhat'], squared=False)\n",
    "\n",
    "        #save result\n",
    "        rmse_dict_reg_test[location_id] = rmse_test_reg\n",
    "    else:\n",
    "        #save empty result\n",
    "        rmse_dict_reg_test[location_id] = None\n",
    "\n",
    "    # train data\n",
    "    # use complete train\n",
    "    df_rmse_train_reg = df_location_reg[['ds','y']]\n",
    "    # merge forecast to train data\n",
    "    df_rmse_train_reg = df_rmse_train_reg.merge(forecast_reg[['yhat', 'ds']], how='left', left_on='ds', right_on='ds').drop(columns='ds', axis=1)\n",
    "    # drop NaN    \n",
    "    df_rmse_train_reg.dropna(inplace=True)\n",
    "    # calculate rmse for specific time span\n",
    "    rmse_train_reg = mean_squared_error(df_rmse_train_reg['y'], df_rmse_train_reg['yhat'], squared=False)\n",
    "\n",
    "    #save result\n",
    "    rmse_dict_reg_train[location_id] = rmse_train_reg\n",
    "\n",
    "    # show results\n",
    "    print(f'RMSE test = {None if rmse_test_reg is None else round(rmse_test_reg,2)} µg/m3')\n",
    "    print(f'RMSE train = {round(rmse_train_reg,2)} µg/m3')\n",
    "\n",
    "    end_time = time.time()\n",
    "    time_lapsed = end_time - start_time\n",
    "    time_converted = time_convert(time_lapsed)\n",
    "\n",
    "    #------------------------------------------------------------\n",
    "    # setting the MLFlow connection and experiment\n",
    "    mlflow.set_tracking_uri(TRACKING_URI)\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "    with mlflow.start_run(run_name=run_name): \n",
    "        mlflow.log_params({'seasonality_mode': seasonality_mode, 'yearly_seasonaliy': yearly_seasonality, 'weekly_seasonality': weekly_seasonality, 'daily_seasonality': daily_seasonality,\n",
    "                'growth': growth, 'n_changepoints': n_changepoints,\n",
    "                'temp_prior_scale': temp_prior_scale, 'humi_prior_scale': humi_prior_scale, 'press_prior_scale': press_prior_scale, 'windsp_prior_scale': windsp_prior_scale, 'winddir_prior_scale': winddir_prior_scale, 'precip_prior_scale': precip_prior_scale,\n",
    "                'temp_flag': temp_flag, 'humi_flag': humi_flag, 'press_flag': press_flag, 'windsp_flag': windsp_flag, 'winddir_flag': winddir_flag, 'precip_flag': precip_flag, \n",
    "                'cap': cap, 'floor': floor,\n",
    "                'location_id': location_id\n",
    "                })\n",
    "\n",
    "        mlflow.set_tags({'location_id': location_id, 'city': city, 'runtime': time_converted})\n",
    "        mlflow.log_metrics({'RMSE_train': rmse_train_reg, 'RMSE_test': rmse_test_reg})\n",
    "    mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_with_future(model, forecast, future, file):\n",
    "    # train data and predition\n",
    "    fig = model.plot(forecast, xlabel='Date', ylabel='Value', figsize=(20, 6))\n",
    "    ax = fig.gca()\n",
    "    \n",
    "    # test data\n",
    "    sns.scatterplot(data=future, x='timestamp', y='PM2p5', ax=ax, color='green')\n",
    "    plt.title(f'location {location_id}', fontsize=34)\n",
    "    ax.set_xlabel(\"Date\", size=34)\n",
    "    ax.set_ylabel(\"PM 2.5 in µg/m³\", size=34)\n",
    "    ax.tick_params(axis=\"x\", labelsize=24)\n",
    "    ax.tick_params(axis=\"y\", labelsize=24)\n",
    "    ax.set_ylim(0, cap * 2)\n",
    "    ax.set_xlim(min(df.query(f'location_id == {location_id}').timestamp), max(df.query(f'location_id == {location_id}').timestamp) + datetime.timedelta(hours=prediction_time))\n",
    "\n",
    "    #save figure\n",
    "    fig.savefig(file, bbox_inches='tight', facecolor=\"#EEEEEE\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot models\n",
    "for location_id in location_list_reg[:NUMBER_OF_MODELS_REG]:\n",
    "    model_reg = prophet_models_per_location_reg[location_id]\n",
    "    # limit test data to current location\n",
    "    df_test_location = df_test_data[df_test_data['location_id'] == location_id]\n",
    "    plot_model_with_future(model_reg, prophet_forecasts_per_location_reg[location_id], df_test_location, f'../images/prophet_reg_location_id_{location_id}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot components of models\n",
    "for location_id in location_list_reg[:NUMBER_OF_MODELS_REG]:\n",
    "    model_reg = prophet_models_per_location_reg[location_id]\n",
    "    fig2 = model_reg.plot_components(prophet_forecasts_per_location_reg[location_id], figsize=(15, 8))\n",
    "    plt.title(f'location {location_id}')\n",
    "\n",
    "    fig2.savefig(f'../images/prophet_components_reg_location_id_{location_id}.png', bbox_inches='tight', facecolor=\"#EEEEEE\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd274dd0e888e4827d27c0f0cddff490366d06b521b28e260a17e10b7541cd62"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
