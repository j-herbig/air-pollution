{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data merging\n",
    "The data for this project consists of open source data provided by [Sensor Community](https://sensor.community/en/) and [Deutscher Wetterdienst](https://opendata.dwd.de/climate_environment/CDC/observations_germany/). We focus on the following sensor positions and time spans:\n",
    "| city | mean PM pollution of today | longitude | latitude | time span |\n",
    "|---|---|---|---|---|\n",
    "| Bremen   | homogeneous, low  | 8.670000 - 8.933400 | 53.013000 - 53.145600 | Jan 20 - Feb 22 | \n",
    "| Frankfurt | inhomogeneous, high | 8.430634 - 8.919868 | 50.030681 - 50.205692 | Jan 20 - Feb 22 |\n",
    "\n",
    "This data includes a good variety as the particulate matter (PM) pollution in Bremen is homogeneously low, whereupon it's unhomogeneous and quite high in mean Frankfurt.\n",
    "\n",
    "The contributors to the Sensor Community use different sensors that are installed on private property. The different sensors measure the following values:\n",
    "| sensor name | time stamp | temperature (°C) | PM2.5 (µg/m<sup>3</sup>) | PM10 (µg/m<sup>3</sup>) | air pressure | humidity |\n",
    "|---|---|---|---|---|---|---|\n",
    "| sds011 | x |   | x | x |   |   |\n",
    "| bme280 | x | x |   |   | x | x |\n",
    "| bmp280 | x | x |   |   | x | x |\n",
    "| dht22  | x | x |   |   |   | x |\n",
    "\n",
    "As a consequence and because sensors of different contributors can be situated at the same longitude/latitude-position the data can comprise several measurements per site. \n",
    "\n",
    "The measurement rate is with about 20 measurements per hour higher than needed. To reduce the data size mean values per hour and per longitude/latitude-position are calculated together with standard deviations.\n",
    "\n",
    "Before calculating mean values we proof if the sensors measure within the expected range and how many values are missing.\n",
    "\n",
    "In this notebook the following will be done:\n",
    "* extracting data from Sensor Community\n",
    "* checking for inconsistencies \n",
    "* merging data into one DataFrame and calculating mean values per hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fundamentals\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# select path to data\n",
    "import glob\n",
    "\n",
    "# plt.rcParams.update({'figure.facecolor':'white'})   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data from Sensor Community\n",
    "The complete data for one data type is loaded by means of a function.  Unnecessary(empty) columns are dropped. Based on the time stamp columns for data and hour are added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_sensor_data(sensor):\n",
    "    '''\n",
    "    imports the data for a given sensor type (sds, bme, bmp, dht)\n",
    "    returns list with DataFrames with one entry per sensor\n",
    "    '''\n",
    "    path = r'../data/SensorCommunity' # use your path\n",
    "    all_files = glob.glob(path + \"/*.csv\") # list with paths to data files\n",
    "\n",
    "    li = []\n",
    "    # select data files for chosen sensor, read it to DataFrame and save it in list\n",
    "    for filename in all_files: \n",
    "        if sensor in filename:\n",
    "            df = pd.read_csv(filename, index_col=None, header=0)\n",
    "            li.append(df)\n",
    "\n",
    "    return pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "def process_timestamps(df):\n",
    "    # add columns with date and hour\n",
    "    df.timestamp = pd.to_datetime(df.timestamp)\n",
    "    df['hour'] = df.timestamp.dt.hour\n",
    "    df['date'] = pd.to_datetime(df.timestamp.dt.date)\n",
    "    df.drop('timestamp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and drop unnecessary columns\n",
    "df_sds = import_sensor_data(\"sds\").drop(['durP1', 'durP2', 'ratioP1', 'ratioP2', 'sensor_type', 'sensor_id', 'location'], axis=1)\n",
    "df_bme280 = import_sensor_data(\"bme280\").drop(['altitude', 'pressure_sealevel', 'sensor_type', 'sensor_id', 'location'], axis=1)\n",
    "df_bmp280 = import_sensor_data(\"bmp280\").drop(['altitude', 'pressure_sealevel', 'sensor_type', 'sensor_id', 'location'], axis=1)\n",
    "df_dht22 = import_sensor_data(\"dht22\").drop(['sensor_type', 'sensor_id', 'location'], axis=1)\n",
    "\n",
    "# df_bmp180 = import_sensor_data(\"bmp180\").drop(['altitude', 'pressure_sealevel', 'sensor_type', 'location'], axis=1)\n",
    "# df_ds18b20 = import_sensor_data(\"ds18b20\").drop(['sensor_type', 'location'], axis=1)\n",
    "\n",
    "dataframes = [df_sds, df_bme280, df_bmp280, df_dht22]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make date and hour columns\n",
    "for df in dataframes:\n",
    "    process_timestamps(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for inconsistencies\n",
    "For the particular matter (PM) sensor sds011 the measurement range is given in the data sheet as (0.0-999.9) μg /m<sup>3</sup>. This means that beyond 999.9 μg /m<sup>3</sup> the sensor is still measuring something, but the absolute values are not trustworthy. Overall a constant value for a long time points to some measurement problems. For this first of all we check for 0-measurements for the PM10 sensor P1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for 0-measurements and sort descending \n",
    "df_sds.query(\"P1==0\").groupby(['lat', 'lon']).count().sort_values('P1', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for 0-measurements and sort descending \n",
    "df_sds.query(\"P2==999.9\").groupby(['lat', 'lon']).count().sort_values('P2', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sds.query(\"P1==1999.9\").groupby(['lat', 'lon']).count().sort_values('P1', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for 0-measurements and sort descending \n",
    "df_sds.query(\"P1==1999.9 and P2==999.9\").groupby(['lat', 'lon']).count().sort_values('P1', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count exemplarily total number of measurements \n",
    "df_sds.query(\"lat==50.08600 and lon==8.63400\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sds['date_hour'] = df_sds['date'].astype(str) + '_' + df_sds['hour'].astype(str)\n",
    "print(df_sds.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(25, 15))\n",
    "ax = sns.lineplot(data=df_sds.query(\"lat==50.08600 and lon==8.63400\")[::100], x='date_hour', y='P2')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylim(-2, 50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 15))\n",
    "ax = sns.lineplot(data=df_sds.query(\"lat==53.068 and lon==8.818\")[::100], x='date_hour', y='P2')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylim(-2, 50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_sds_grouped = df_sds.groupby(['hour', 'date', 'lat', 'lon']).mean().reset_index()\n",
    "df_sds_grouped_std = df_sds.groupby(['hour', 'date', 'lat', 'lon']).std().reset_index()\n",
    "\n",
    "df_sds_grouped_std.rename(columns={'P1': 'PM10_std', 'P2': 'PM2p5_std'}, inplace=True)\n",
    "df_sds_grouped.rename(columns={'P1': 'PM10', 'P2': 'PM2p5'}, inplace=True)\n",
    "\n",
    "df_sds_merged = df_sds_grouped.merge(df_sds_grouped_std, how='left', on=['hour', 'date', 'lat', 'lon'])\n",
    "\n",
    "df_sds_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_environment = pd.concat([df_bme280, df_bmp280, df_dht22], axis=0)\n",
    "df_environment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_environment.query(\"hour==0 and date=='2020-01-01' and lat==50.042000 and lon==8.436000\")['temperature'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_environment_grouped = df_environment.groupby(['hour', 'date', 'lat', 'lon']).mean().reset_index()\n",
    "df_environment_grouped_std = df_environment.groupby(['hour', 'date', 'lat', 'lon']).std().reset_index()\n",
    "\n",
    "df_environment_grouped_std.rename(columns={'pressure': 'pressure_std', 'temperature': 'temperature_std', 'humidity': 'humidity_std'}, inplace=True)\n",
    "df_environment_merged = df_environment_grouped.merge(df_environment_grouped_std, how='left', on=['hour', 'date', 'lat', 'lon'])\n",
    "df_environment_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_environment_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_environment_merged.columns:\n",
    "    print(f\"{col}: {df_environment_merged[col].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_sds_merged.merge(df_environment_merged, how='left', on=['hour', 'date', 'lat', 'lon'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0eff187d94a6d345964e064b31a9e6fc453a64676d5a266be90b3132f78586ec"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
