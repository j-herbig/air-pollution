{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CDC - Observations Germany](https://opendata.dwd.de/climate_environment/CDC/observations_germany/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wind data\n",
    "[Wind historical](https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/10_minutes/wind/historical/) </br>\n",
    "[Wind recent](https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/10_minutes/wind/recent/) </br></br>\n",
    "[Extreme Wind historical](https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/10_minutes/extreme_wind/historical/) </br>\n",
    "[Extreme Wind recent](https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/10_minutes/extreme_wind/recent/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precipitation data\n",
    "[Precipitation historical](https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/10_minutes/precipitation/historical/) </br>\n",
    "[Precipitation recent](https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/10_minutes/precipitation/recent/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import zipfile\n",
    "\n",
    "\n",
    "# not all data are available in every temporal resolution!\n",
    "DATA = [\n",
    "    'air_temperature',\n",
    "    # 'cloud_type',\n",
    "    # 'cloudiness',\n",
    "    # 'dew_point',\n",
    "    'extreme_wind',\n",
    "    # 'moisture',\n",
    "    'precipitation',\n",
    "    # 'pressure',\n",
    "    # 'soil',\n",
    "    # 'soil_temperature',\n",
    "    # 'solar',\n",
    "    # 'sun',\n",
    "    # 'standard_format',\n",
    "    # 'visibility',\n",
    "    # 'weather_phenomena',\n",
    "    'wind',\n",
    "    # 'wind_test',\n",
    "    # 'wind_synop',\n",
    "]\n",
    "\n",
    "TEMPORAL_RES = [\n",
    "    # '1_minute',\n",
    "    '10_minutes',\n",
    "    # 'hourly',\n",
    "    # 'subdaily',\n",
    "    # 'daily',\n",
    "    # 'monthly',\n",
    "    # 'annual',\n",
    "    # 'multi_annual',\n",
    "]\n",
    "\n",
    "PERIOD = [\n",
    "    # 'start - 2020', # in hourly data\n",
    "\n",
    "    # '1991', # in 10_minutes data\n",
    "    # '2000 - 2009', # in 10_minutes data\n",
    "    # '2010 - 2019', # in 10_minutes data\n",
    "    '2020 - 2021', # in 10_minutes data\n",
    "    'recent', \n",
    "]\n",
    "\n",
    "STATIONS_ID = [\n",
    "    '691', # Bremen\n",
    "    '1420', # Frankfurt a. M.\n",
    "\n",
    "]\n",
    "\n",
    "ROOT_URL = \"https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/\"\n",
    "\n",
    "DOWNLOAD_DIR = os.path.join(os.curdir, \"../data\", \"DeutscherWetterdienst\", \"\")\n",
    "\n",
    "# make target directory, if it doesn't exist\n",
    "if not os.path.exists(DOWNLOAD_DIR):\n",
    "    os.mkdir(DOWNLOAD_DIR)\n",
    "\n",
    "# ensure that the id has 5 digits\n",
    "for i, s_id in enumerate(STATIONS_ID):\n",
    "    while len(s_id) < 5:\n",
    "        s_id = '0' + s_id\n",
    "    STATIONS_ID[i] = s_id\n",
    "\n",
    "# get urls to search for downloadable data\n",
    "urls_root = []\n",
    "for temp_res in TEMPORAL_RES:\n",
    "    for dat in DATA:\n",
    "        if 'recent' in PERIOD:\n",
    "            urls_root.append(ROOT_URL + temp_res + '/' + dat + '/' + 'recent' + '/')\n",
    "        if len(PERIOD) > 1 or PERIOD[0] != 'recent':\n",
    "            urls_root.append(ROOT_URL + temp_res + '/' + dat + '/' + 'historical' + '/')\n",
    "\n",
    "# get relevant years, 'akt' for recent data \n",
    "years = [y.split(' - ')[1] if len(y.split('-')) > 1 else y.split(' - ')[0] for y in PERIOD]\n",
    "if 'recent' in PERIOD:\n",
    "    years.append('akt')\n",
    "\n",
    "# get urls and names of desired files\n",
    "urls = []\n",
    "names = []\n",
    "for url in urls_root:\n",
    "    # get html of website\n",
    "    r = requests.get(url)\n",
    "    soup = bs(r.text)\n",
    "    # find download links and filter for .zip files, station and relevant time periods\n",
    "    for i, link in enumerate(soup.findAll('a')):\n",
    "        if '.zip' in str(link) and \\\n",
    "            any([station in str(link) for station in STATIONS_ID]) and \\\n",
    "                any([year in str(link) for year in years]):\n",
    "            url_download = url + link.get('href')\n",
    "            urls.append(url_download)\n",
    "            names.append(soup.select('a')[i].attrs['href'])\n",
    "\n",
    "names_urls = zip(names, urls)\n",
    "\n",
    "# download files\n",
    "for name, url in names_urls:\n",
    "    \n",
    "    file_path = os.path.join(DOWNLOAD_DIR, name)\n",
    "    file_path_txt = os.path.join(DOWNLOAD_DIR, name.split('.')[0] + '.txt')\n",
    "    if not os.path.isfile(file_path) and not os.path.isfile(file_path_txt):\n",
    "        response = requests.get(url, timeout=50)\n",
    "        print(url)\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "        # unzip file\n",
    "        if os.path.isfile(file_path):\n",
    "            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(DOWNLOAD_DIR)\n",
    "\n",
    "    # delete .zip\n",
    "    if os.path.isfile(file_path):\n",
    "        os.remove(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1d0c01c3ebde60b56da9ded1d66f0f72d104a2bb1824316bb4aff32e9a24f56"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
