{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CDC - Observations Germany](https://opendata.dwd.de/climate_environment/CDC/observations_germany/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wind data\n",
    "[Wind historical](https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/10_minutes/wind/historical/) </br>\n",
    "[Wind recent](https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/10_minutes/wind/recent/) </br></br>\n",
    "[Extreme Wind historical](https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/10_minutes/extreme_wind/historical/) </br>\n",
    "[Extreme Wind recent](https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/10_minutes/extreme_wind/recent/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precipitation data\n",
    "[Precipitation historical](https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/10_minutes/precipitation/historical/) </br>\n",
    "[Precipitation recent](https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/10_minutes/precipitation/recent/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download data\n",
    "Run the following script completely to get the desired data from Deutscher Wetterdienst.\n",
    "\n",
    "Information:\n",
    "Since 'recent' only covers the last 520 days, we need to also download 'historical' data in a loop over two periods.\n",
    "\n",
    "1. PERIOD = ['2020-2022', 'recent']\n",
    "2. PERIOD = ['2020 - 2020', 'historical']\n",
    "\n",
    "Desired config parameters:\n",
    "\n",
    "DATA = ['air_temperature', 'pressure', 'precipitation', 'wind'], \n",
    "\n",
    "STATIONS_ID = ['691', '1420'] --> Bremen and Frankfurt a. M.\n",
    "\n",
    "TEMPORAL_RES = ['hourly']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import zipfile\n",
    "\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/air_temperature/recent/stundenwerte_TU_00691_akt.zip\n",
      "https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/air_temperature/recent/stundenwerte_TU_01420_akt.zip\n",
      "https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/precipitation/recent/stundenwerte_RR_00691_akt.zip\n",
      "https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/precipitation/recent/stundenwerte_RR_01420_akt.zip\n",
      "https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/pressure/recent/stundenwerte_P0_00691_akt.zip\n",
      "https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/pressure/recent/stundenwerte_P0_01420_akt.zip\n",
      "https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/wind/recent/stundenwerte_FF_00691_akt.zip\n",
      "https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/wind/recent/stundenwerte_FF_01420_akt.zip\n",
      "https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/air_temperature/historical/stundenwerte_TU_00691_19490101_20201231_hist.zip\n",
      "https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/air_temperature/historical/stundenwerte_TU_01420_19810101_20201231_hist.zip\n",
      "https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/precipitation/historical/stundenwerte_RR_00691_19950901_20201231_hist.zip\n",
      "https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/precipitation/historical/stundenwerte_RR_01420_19950901_20201231_hist.zip\n",
      "https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/pressure/historical/stundenwerte_P0_00691_19490101_20201231_hist.zip\n",
      "https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/pressure/historical/stundenwerte_P0_01420_19490101_20201231_hist.zip\n",
      "https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/wind/historical/stundenwerte_FF_00691_19260101_20201231_hist.zip\n",
      "https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/wind/historical/stundenwerte_FF_01420_19670101_20201231_hist.zip\n"
     ]
    }
   ],
   "source": [
    "# list of periods to loop over\n",
    "periods = [['2020 - 2022', 'recent'],\n",
    "        ['2020 - 2020', 'historical']]\n",
    "\n",
    "\n",
    "# not all data are available in every temporal resolution!\n",
    "DATA = [\n",
    "    'air_temperature',\n",
    "    # 'cloud_type',\n",
    "    # 'cloudiness',\n",
    "    # 'dew_point',\n",
    "    #'extreme_wind',\n",
    "    # 'moisture',\n",
    "    'precipitation',\n",
    "    'pressure',\n",
    "    # 'soil',\n",
    "    # 'soil_temperature',\n",
    "    # 'solar',\n",
    "    # 'sun',\n",
    "    # 'standard_format',\n",
    "    # 'visibility',\n",
    "    # 'weather_phenomena',\n",
    "    'wind',\n",
    "    # 'wind_test',\n",
    "    # 'wind_synop',\n",
    "]\n",
    "\n",
    "TEMPORAL_RES = [\n",
    "    # '1_minute',\n",
    "    #'10_minutes',\n",
    "    'hourly',\n",
    "    # 'subdaily',\n",
    "    # 'daily',\n",
    "    # 'monthly',\n",
    "    # 'annual',\n",
    "    # 'multi_annual',\n",
    "]\n",
    "\n",
    "# now dynamically looped over to cover different periods\n",
    "# PERIOD = [\n",
    "#     # 'start - 2020', # in hourly data\n",
    "\n",
    "#     # '1991', # in 10_minutes data\n",
    "#     # '2000 - 2009', # in 10_minutes data\n",
    "#     # '2010 - 2019', # in 10_minutes data\n",
    "#     '2020 - 2020', # in 10_minutes data\n",
    "#     #'recent', \n",
    "#     'historical'\n",
    "# ]\n",
    "\n",
    "STATIONS_ID = [\n",
    "    '691', # Bremen\n",
    "    '1420', # Frankfurt a. M.\n",
    "]\n",
    "\n",
    "ROOT_URL = \"https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/\"\n",
    "\n",
    "DOWNLOAD_DIR = os.path.join(os.curdir, \"../data\", \"DeutscherWetterdienst\", \"\")\n",
    "\n",
    "# make target directory, if it doesn't exist\n",
    "if not os.path.exists(DOWNLOAD_DIR):\n",
    "    os.mkdir(DOWNLOAD_DIR)\n",
    "\n",
    "# ensure that the id has 5 digits\n",
    "for i, s_id in enumerate(STATIONS_ID):\n",
    "    while len(s_id) < 5:\n",
    "        s_id = '0' + s_id\n",
    "    STATIONS_ID[i] = s_id\n",
    "\n",
    "\n",
    "for PERIOD in periods:\n",
    "    # get urls to search for downloadable data\n",
    "    urls_root = []\n",
    "    for temp_res in TEMPORAL_RES:\n",
    "        for dat in DATA:\n",
    "            if 'recent' in PERIOD:\n",
    "                urls_root.append(ROOT_URL + temp_res + '/' + dat + '/' + 'recent' + '/')\n",
    "            if len(PERIOD) > 1 or PERIOD[0] != 'recent':\n",
    "                urls_root.append(ROOT_URL + temp_res + '/' + dat + '/' + 'historical' + '/')\n",
    "\n",
    "    # get relevant years, 'akt' for recent data \n",
    "    years = [y.split(' - ')[1] if len(y.split('-')) > 1 else y.split(' - ')[0] for y in PERIOD]\n",
    "    if 'recent' in PERIOD:\n",
    "        years.append('akt')\n",
    "\n",
    "    # get urls and names of desired files\n",
    "    urls = []\n",
    "    names = []\n",
    "    for url in urls_root:\n",
    "        # get html of website\n",
    "        r = requests.get(url)\n",
    "        soup = bs(r.text)\n",
    "        # find download links and filter for .zip files, station and relevant time periods\n",
    "        for i, link in enumerate(soup.findAll('a')):\n",
    "            if '.zip' in str(link) and \\\n",
    "                any([station in str(link) for station in STATIONS_ID]) and \\\n",
    "                    any([year in str(link) for year in years]):\n",
    "                url_download = url + link.get('href')\n",
    "                urls.append(url_download)\n",
    "                names.append(soup.select('a')[i].attrs['href'])\n",
    "\n",
    "    names_urls = zip(names, urls)\n",
    "\n",
    "    # download files\n",
    "    for name, url in names_urls:\n",
    "        \n",
    "        file_path = os.path.join(DOWNLOAD_DIR, name)\n",
    "        file_path_txt = os.path.join(DOWNLOAD_DIR, name.split('.')[0] + '.txt')\n",
    "        if not os.path.isfile(file_path) and not os.path.isfile(file_path_txt):\n",
    "            response = requests.get(url, timeout=50)\n",
    "            print(url)\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "            # unzip file\n",
    "            if os.path.isfile(file_path):\n",
    "                with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                    zip_ref.extractall(DOWNLOAD_DIR)\n",
    "\n",
    "        # delete .zip\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Combine data of cities and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all meteorological data for a city from 'data/DeutscherWetterdienst'\n",
    "def read_city_data(city_codes):\n",
    "    \"\"\"Reads all data of different cities and metrics\n",
    "\n",
    "    Args:\n",
    "        city_codes (list): list of city codes to be processed\n",
    "\n",
    "    Returns:\n",
    "        dictionary: dictionary of different dataframes per metric, city code and period (recent - 2 or historic - 1)\n",
    "    \"\"\"\n",
    "    path = r'../data/DeutscherWetterdienst' \n",
    "    all_files = glob.glob(path + \"/produkt*.txt\") \n",
    "\n",
    "    weather_metrics = {}    \n",
    "    for filename in all_files: \n",
    "            # loop over all cities in parameterization\n",
    "            for city_code in city_codes:\n",
    "                if city_code in filename:\n",
    "                    df = pd.read_csv(filename, sep=';')\n",
    "                    df['date'] = pd.to_datetime(df.MESS_DATUM, format='%Y%m%d%H')\n",
    "                    df.drop(['eor', 'MESS_DATUM', df.columns[df.columns.str.startswith('QN')][0]], axis=1, inplace=True)\n",
    "                    df = df.query(\"date < '2022-03' and date >= '2020-01'\")\n",
    "                    # keys of dictionary consist of measurement name, city code and first digit of period YYYY (1 or 2)\n",
    "                    weather_metrics[f'{filename[38:40] + filename[-9:-4] + filename[48]}'] = df\n",
    "    return weather_metrics\n",
    "\n",
    "# Concatenate historical and current data for each metric\n",
    "def concat_city_data(metrics_dict):\n",
    "    \"\"\"Concatenate all data per metric\n",
    "\n",
    "    Args:\n",
    "        metrics_dict (dictionary): dictionary of dataframes per metric, city code and period (recent - 2 or historic - 1)\n",
    "\n",
    "    Returns:\n",
    "        list: list of dataframes (one per metric), containing historical and current data for all cities\n",
    "    \"\"\"\n",
    "    concatenated_metrics = []\n",
    "    # loop over different metrics\n",
    "    for metric in set([x[:-6] for x in list(metrics_dict.keys())]):\n",
    "        # get all corresponding keys for one metric (includes recent and historic data and all cities)\n",
    "        metric_keys = [x for x in list(metrics_dict.keys()) if metric in x]\n",
    "        # create list of all dataframes for one metric (for all cities)\n",
    "        metric_dfs = [metrics_dict[x] for x in metric_keys]\n",
    "        concatenated_metrics.append(pd.concat(metric_dfs, axis=0, ignore_index=True).drop_duplicates(keep='first'))\n",
    "    return concatenated_metrics\n",
    "\n",
    "\n",
    "# Merge all meterological data into one dataframe for all cities and metrics\n",
    "def merge_city_data(df_list):\n",
    "    \"\"\"Merge all data into one dataframe for different metrics\n",
    "\n",
    "    Args:\n",
    "        df_list (list): list of dataframes for different metrics\n",
    "\n",
    "    Returns:\n",
    "        dataframe: one dataframe with all metrics\n",
    "    \"\"\"\n",
    "    df_merged = df_list[0]\n",
    "    for df in df_list[1:]:\n",
    "        df_merged = df_merged.merge(df, on=['date', 'STATIONS_ID'], how='left')\n",
    "    df_merged.sort_values('date', ascending=True, inplace=True)\n",
    "    return df_merged\n",
    "\n",
    "\n",
    "def label_cities(stations_id):\n",
    "    \"\"\"Create label from stations_id\n",
    "\n",
    "    Args:\n",
    "        stations_id (string): string of stations_id for city\n",
    "\n",
    "    Returns:\n",
    "        string: corresponding label for given stations_id\n",
    "    \"\"\"\n",
    "    if (stations_id==1420):\n",
    "        return 'Frankfurt'\n",
    "    elif (stations_id==691):\n",
    "        return 'Bremen'\n",
    "    # add new cities here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for all cities (global variable STATIONS_ID) and metrics\n",
    "# append the three functions defined above and call them with parameter for list of stations_ids\n",
    "dwd_all_cities = merge_city_data(concat_city_data(read_city_data(STATIONS_ID)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add city column (e.g. Frankfurt, Bremen)\n",
    "dwd_all_cities['City'] = dwd_all_cities.apply(lambda x: label_cities(x.STATIONS_ID), axis=1)\n",
    "# drop column STATIONS_ID because it is no longer needed\n",
    "# drop PrecipitationIndicator\n",
    "dwd_all_cities.drop(['STATIONS_ID', 'RS_IND'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns into readable format\n",
    "dwd_all_cities = dwd_all_cities.rename(columns = {'RF_TU': 'humidity', 'TT_TU': 'temperature', '  R1': 'precip', '   F': 'wind_speed', '   D': 'wind_direction', '   P': 'pressure_sealevel', '  P0': 'pressure'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pressure_sealevel</th>\n",
       "      <th>pressure</th>\n",
       "      <th>date</th>\n",
       "      <th>precip</th>\n",
       "      <th>WRTR</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12984</th>\n",
       "      <td>1035.5</td>\n",
       "      <td>1034.8</td>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>250.0</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Bremen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18960</th>\n",
       "      <td>1036.5</td>\n",
       "      <td>1023.1</td>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Frankfurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12985</th>\n",
       "      <td>1035.1</td>\n",
       "      <td>1034.4</td>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Bremen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18961</th>\n",
       "      <td>1036.3</td>\n",
       "      <td>1022.9</td>\n",
       "      <td>2020-01-01 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Frankfurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18962</th>\n",
       "      <td>1036.2</td>\n",
       "      <td>1022.8</td>\n",
       "      <td>2020-01-01 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>92.0</td>\n",
       "      <td>Frankfurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37917</th>\n",
       "      <td>1031.7</td>\n",
       "      <td>1018.5</td>\n",
       "      <td>2022-02-28 21:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Frankfurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37918</th>\n",
       "      <td>1031.5</td>\n",
       "      <td>1018.3</td>\n",
       "      <td>2022-02-28 22:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Frankfurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12982</th>\n",
       "      <td>1031.4</td>\n",
       "      <td>1030.7</td>\n",
       "      <td>2022-02-28 22:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Bremen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12983</th>\n",
       "      <td>1030.9</td>\n",
       "      <td>1030.2</td>\n",
       "      <td>2022-02-28 23:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Bremen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37919</th>\n",
       "      <td>1031.6</td>\n",
       "      <td>1018.3</td>\n",
       "      <td>2022-02-28 23:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Frankfurt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37920 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pressure_sealevel  pressure                date  precip   WRTR  \\\n",
       "12984             1035.5    1034.8 2020-01-01 00:00:00     0.0 -999.0   \n",
       "18960             1036.5    1023.1 2020-01-01 00:00:00     0.0 -999.0   \n",
       "12985             1035.1    1034.4 2020-01-01 01:00:00     0.0    0.0   \n",
       "18961             1036.3    1022.9 2020-01-01 01:00:00     0.0    0.0   \n",
       "18962             1036.2    1022.8 2020-01-01 02:00:00     0.0    0.0   \n",
       "...                  ...       ...                 ...     ...    ...   \n",
       "37917             1031.7    1018.5 2022-02-28 21:00:00     0.0 -999.0   \n",
       "37918             1031.5    1018.3 2022-02-28 22:00:00     0.0    0.0   \n",
       "12982             1031.4    1030.7 2022-02-28 22:00:00     0.0    0.0   \n",
       "12983             1030.9    1030.2 2022-02-28 23:00:00     0.0    0.0   \n",
       "37919             1031.6    1018.3 2022-02-28 23:00:00     0.0    0.0   \n",
       "\n",
       "       wind_speed  wind_direction  temperature  humidity       City  \n",
       "12984         0.7           250.0         -1.8     100.0     Bremen  \n",
       "18960         2.7            40.0          0.0      90.0  Frankfurt  \n",
       "12985         1.2           180.0         -0.9     100.0     Bremen  \n",
       "18961         2.8            20.0          0.1      90.0  Frankfurt  \n",
       "18962         2.2            70.0         -1.1      92.0  Frankfurt  \n",
       "...           ...             ...          ...       ...        ...  \n",
       "37917         2.0            50.0          1.8      61.0  Frankfurt  \n",
       "37918         1.9            60.0          2.0      61.0  Frankfurt  \n",
       "12982         5.6           130.0          1.5      76.0     Bremen  \n",
       "12983         4.8           130.0          1.5      74.0     Bremen  \n",
       "37919         2.2            60.0         -0.3      70.0  Frankfurt  \n",
       "\n",
       "[37920 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dwd_all_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as csv\n",
    "dwd_all_cities.to_csv('../data/processed_deutscher_wetterdienst.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1d0c01c3ebde60b56da9ded1d66f0f72d104a2bb1824316bb4aff32e9a24f56"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
