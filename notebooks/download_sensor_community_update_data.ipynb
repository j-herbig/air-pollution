{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "MONTH_START = \"2022-03\" # Start month in the format yyyy-mm\n",
    "MONTH_COUNT = 1 # sensor data will be downloaded for this amount of months\n",
    "ROOT_URL = \"https://archive.sensor.community/\"\n",
    "ROOT_DIR = '../data/SensorCommunity/'\n",
    "WAIT_BETWEEN_DOWNLOADS = (0, 1)\n",
    "SENSORS = [\n",
    "    # 'bme280', \n",
    "    # 'bmp180', \n",
    "    # 'bmp280', \n",
    "    # 'dht22',\n",
    "    # 'ds18b20', \n",
    "    # 'hpm', \n",
    "    # 'htu21d', \n",
    "    # 'pms1003', \n",
    "    # 'pms3003', \n",
    "    # 'pms5003', \n",
    "    # 'pms6003', \n",
    "    # 'pms7003', \n",
    "    # 'ppd42ns', \n",
    "    'sds011',\n",
    "]\n",
    "LAT_RANGE = [\n",
    "    (53.013, 53.1456), \n",
    "    (50.030681, 50.205692),\n",
    "]\n",
    "# Bremen: (53.013, 53.1456)\n",
    "# Frankfurt a. M.: (50.030681, 50.205692)\n",
    "LON_RANGE = [\n",
    "    (8.67, 8.9334), \n",
    "    (8.430634, 8.919868),\n",
    "]\n",
    "\n",
    "\n",
    "# get all csv files in root directory and the current date\n",
    "all_files = glob.glob(ROOT_DIR + \"/*.csv\")\n",
    "today = datetime.today()\n",
    "\n",
    "# loop over all defined sensors\n",
    "for sensor in SENSORS:\n",
    "    # store the corresponding files in a list and sort it\n",
    "    sensor_files = []   \n",
    "    for file in all_files:\n",
    "        if sensor in file:\n",
    "            sensor_files.append(file)\n",
    "    sensor_files.sort(reverse=True)\n",
    "\n",
    "    # get the first date that is not already in the monthly csv\n",
    "    start_date = None\n",
    "    # If the latest file includes 'daily', it could be incomplete.\n",
    "    # Then get the date from the timestamps.\n",
    "    if 'daily' in sensor_files[0]:\n",
    "        df_daily_last = pd.read_csv(sensor_files[0])\n",
    "        start_date = pd.to_datetime(df_daily_last['timestamp']).dt.date.max()\n",
    "        month = start_date.month\n",
    "        start_date += pd.Timedelta(1, unit='days')\n",
    "    # else: get the date from the filename\n",
    "    else:\n",
    "        start_year = int(sensor_files[0].split('-')[0][-4:])\n",
    "        start_month = int(sensor_files[0].split('_')[0][-2:]) + 1\n",
    "        if start_month > 12:\n",
    "            start_month = 1\n",
    "            start_year += 1\n",
    "        start_date = pd.to_datetime(f\"{start_year}-0{start_month}-01\").date()\n",
    "    # make a date range of the dates between start_date and today\n",
    "    dates = pd.date_range(start_date, today, freq='d')\n",
    "    \n",
    "    # get the sensor IDs from previous months' files\n",
    "    sensor_ids = pd.Series(dtype=int)\n",
    "    for i in range(12):\n",
    "        df_old = pd.read_csv(sensor_files[i])\n",
    "        sensor_ids = pd.concat([sensor_ids, pd.Series(df_old['sensor_id'].unique())])\n",
    "    sensor_ids = sensor_ids.unique()\n",
    "\n",
    "    # make possible download URLs from date, sensor and sensor_id\n",
    "    possible_urls = {}\n",
    "    for date in dates:\n",
    "        for sensor_id in sensor_ids:\n",
    "            file_name = f\"{date.strftime('%Y-%m-%d')}_{sensor}_sensor_{sensor_id}.csv\"\n",
    "            possible_urls[file_name] = ROOT_URL + str(date.strftime('%Y-%m-%d')) + '/' + file_name\n",
    "\n",
    "    # make a daily folder if it doesn't exist\n",
    "    if not os.path.exists(os.path.join(ROOT_DIR, \"daily\")):\n",
    "        os.mkdir(os.path.join(ROOT_DIR, \"daily\"))\n",
    "\n",
    "    # loop through possible URLs\n",
    "    \n",
    "    for name, url in possible_urls.items():\n",
    "        csv_path = os.path.join(ROOT_DIR, \"daily\", name)\n",
    "        # check if the files were already downloaded\n",
    "        if not os.path.isfile(csv_path):\n",
    "            response = requests.get(url, timeout=50)\n",
    "            # if not: check whether the download URL is valid\n",
    "            if 'The requested URL was not found on this server.' not in str(response.content):\n",
    "                # if it's valid, download the file\n",
    "                with open(csv_path, 'wb') as f:\n",
    "                    f.write(response.content)\n",
    "                print(f\"{name} downloaded\")\n",
    "\n",
    "    # get all daily files\n",
    "    all_daily_files = glob.glob(os.path.join(ROOT_DIR, \"daily\") + \"/*.csv\")\n",
    "\n",
    "    # make_new_files helps afterwards to figure out, \n",
    "    # if we can append the data to an existing file or if we need a new file\n",
    "    make_new_file = False\n",
    "\n",
    "    # load the latest file\n",
    "    df_daily_last = pd.read_csv(sensor_files[0])\n",
    "    # get the last date and add 1 day to get the start_date\n",
    "    last_date = pd.to_datetime(df_daily_last['timestamp']).dt.date.max()\n",
    "    start_date = last_date + pd.Timedelta(1, unit='days')\n",
    "    # if we switched to the next month, we will have to make a new file\n",
    "    if last_date.month != start_date.month:\n",
    "        make_new_file = True\n",
    "        \n",
    "    # make the file name\n",
    "    if start_date.month < 10:\n",
    "        file = ROOT_DIR + f\"{start_date.year}-0{start_date.month}_{sensor}_daily.csv\"\n",
    "    else:\n",
    "        file = ROOT_URL + f\"{start_date.year}-{start_date.month}_{sensor}_daily.csv\"\n",
    "\n",
    "    # loop through all daily files\n",
    "    for daily_file in all_daily_files:\n",
    "        # if they include the relevant month, year and sensor, they are read\n",
    "        if (f\"{start_date.year}-{start_date.month}\" in daily_file or f\"{start_date.year}-0{start_date.month}\" in daily_file) and sensor in daily_file:\n",
    "            df_daily = pd.read_csv(daily_file, sep=';')\n",
    "            # make an empty dataframe for filtered data\n",
    "            # df_daily_filtered = pd.DataFrame()\n",
    "            for j, lat in enumerate(LAT_RANGE):\n",
    "                # filter for the coordinates defined above\n",
    "                df_temp = df_daily[\n",
    "                    (df_daily['lat'] > LAT_RANGE[j][0]) & \\\n",
    "                    (df_daily['lat'] < LAT_RANGE[j][1]) & \\\n",
    "                    (df_daily['lon'] > LON_RANGE[j][0]) & \\\n",
    "                    (df_daily['lon'] < LON_RANGE[j][1])\n",
    "                ]\n",
    "                # append filtered data\n",
    "                # df_daily_filtered = pd.concat([df_daily_filtered, df_temp])\n",
    "                # if we need a new file make one, otherwise append to an existing\n",
    "                if make_new_file:\n",
    "                    df_temp.to_csv(file, header=True, index=False)\n",
    "                    make_new_file = False\n",
    "                else:\n",
    "                    df_temp.to_csv(file, mode='a', header=False, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0eff187d94a6d345964e064b31a9e6fc453a64676d5a266be90b3132f78586ec"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
