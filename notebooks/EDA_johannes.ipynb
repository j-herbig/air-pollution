{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and do basic formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from Deutscher Wetterdienst\n",
    "df_dwd = pd.read_csv(\"../data/processed_deutscher_wetterdienst.csv\", index_col=0)\n",
    "\n",
    "# convert 'date' to datatime and replace invalid values with 'nan'\n",
    "df_dwd.date = pd.to_datetime(df_dwd.date)\n",
    "for col in df_dwd.columns:\n",
    "    df_dwd[col] = df_dwd[col].replace(-999, np.nan)\n",
    "df_dwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data of sensor community\n",
    "df_sc = pd.read_csv(\"../data/processed_sensor_community.csv\", index_col=0)\n",
    "\n",
    "# convert date and timestamp to datetime\n",
    "df_sc.timestamp = pd.to_datetime(df_sc.timestamp)\n",
    "df_sc.date = pd.to_datetime(df_sc.date)\n",
    "\n",
    "# convert pressure to hPa\n",
    "df_sc['pressure'] = df_sc['pressure'] / 100\n",
    "df_sc['pressure_std'] = df_sc['pressure_std'] / 100\n",
    "\n",
    "# add sensor IDs\n",
    "df_sc_location = df_sc.groupby(['lat', 'lon']).count().reset_index()[['lat', 'lon']]\n",
    "df_sc_location['location_id'] = df_sc_location.index+1\n",
    "df_sc = df_sc.merge(df_sc_location, on=['lat', 'lon'], how='left')\n",
    "\n",
    "# define lists with columns\n",
    "non_data_cols = ['location_id', 'timestamp', 'hour', 'date', 'lat', 'lon','city']\n",
    "data_cols = sorted([col for col in list(df_sc.columns) if col not in non_data_cols])\n",
    "data_cols_wo_std = [col for col in data_cols if 'std' not in col]\n",
    "std_cols = [col for col in data_cols if 'std' in col]\n",
    "\n",
    "# reorganize columns: first non-data columns, then sorted data columns\n",
    "df_sc = df_sc.reindex(columns=non_data_cols+data_cols)\n",
    "df_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigation of missing values, zeros and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics of the whole sc dataset\n",
    "df_sc[data_cols_wo_std].describe().T.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics of the sc dataset for Frankfurt\n",
    "df_sc[df_sc['city']=='Frankfurt'][data_cols_wo_std].describe().T.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics of the sc dataset for Bremen\n",
    "df_sc[df_sc['city']=='Bremen'][data_cols_wo_std].describe().T.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PM10: Mean is almost double of the 75th percentile -> Outliers raise the mean extremely </br>\n",
    "PM2.5: similar to PM10, but less extreme </br>\n",
    "humidity: al values (mean, 25th, 50th and 75th percentile) seem to be very large, the max value is above 100, what doesn't make any sense </br>\n",
    "pressure: assuming the units are Pa (1 bar = 100.000 Pa): min value is below 100 -> unrealistic, max value is also unrealistic (more than 60 bar) </br>\n",
    "temperature: std seems very high (54 Â°C), min and max value are unrealistic </br>\n",
    " </br>\n",
    " Bremen vs. Frankfurt </br>\n",
    " PM10 and PM2.5: std for Bremen is double of std for Frankfurt </br>\n",
    " humidity: 50th percentile of Bremen is already 99.9 % what seems quite high\n",
    " pressure and temperature: no obvious unrealistic observations besides the min and max values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"missing values in each column\")\n",
    "for col in df_sc.columns:\n",
    "    print(f\"{col}: {df_sc[col].isna().sum()} ({round(df_sc[col].isna().sum() / df_sc.shape[0] * 100, 1)} %)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"value '0' in each column\")\n",
    "for col in df_sc.columns:\n",
    "    print(f\"{col}: {df_sc[df_sc[col]==0][col].count()} ({round(df_sc[df_sc[col]==0][col].count() / df_sc.shape[0] * 100, 1)} %)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_nan_and_0s(df: pd.DataFrame, cols: list = None) -> pd.DataFrame:\n",
    "    \"\"\"Counts zeros and nans per column.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe to search for zeros and nans.\n",
    "        cols (list, optional): List of columns, if no columns are specified all will be used. Defaults to None.\n",
    "        thresholds (dict, optional): Thresholds for further . Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe containing counts of zeros and nans.\n",
    "    \"\"\"\n",
    "    # use all columns af none were defined\n",
    "    if cols == None:\n",
    "        cols=df.columns\n",
    "    # make a new dataframe and put the defined column names in the first column\n",
    "    df_nan_0 = pd.DataFrame()\n",
    "    df_nan_0['data'] = cols\n",
    "    # calculate missing values and zeros as absolute value and share \n",
    "    df_nan_0['missing_values'] = [df[col].isna().sum() for col in cols]\n",
    "    df_nan_0['missing_values_share'] = [df[col].isna().sum() / df.shape[0] * 100 for col in cols]\n",
    "    df_nan_0['0_values'] = [df[df[col]==0][col].count() for col in cols]\n",
    "    df_nan_0['0_values_share'] = [df[df[col]==0][col].count() / df.shape[0] * 100 for col in cols]\n",
    "\n",
    "    # transpose the dataframe and use the original column names as column names\n",
    "    df_nan_0 = df_nan_0.set_index('data').T.reset_index()\n",
    "    df_nan_0.columns = [name if i>0 else 'metric' for i, name in enumerate(df_nan_0.columns)]\n",
    "    return df_nan_0\n",
    "\n",
    "\n",
    "# find missing values and zeros in the sc dataset\n",
    "df_data_analysis = count_nan_and_0s(df_sc, data_cols)\n",
    "df_data_analysis.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define metrics and columns to plot\n",
    "metrics = [\"missing_values_share\", \"0_values_share\"]\n",
    "ys = sorted(list(df_data_analysis.columns))\n",
    "ys.remove('metric')\n",
    "\n",
    "# define size of subplot\n",
    "columns = 4\n",
    "rows = int(np.ceil((len(df_data_analysis.columns) - 1) / columns))\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(rows, columns, figsize=(20,10)) # create subplots\n",
    "plt.suptitle(\"Data analysis of missing values and zeros\", fontsize=20) # title of plot\n",
    "fig.tight_layout() # tight_layout automatically adjusts subplot params so that the subplot(s) fits in to the figure area\n",
    "plt.subplots_adjust(hspace = .5, wspace = .2, top = .9) # adjusts the space between the single subplots\n",
    "\n",
    "for row in range(rows):\n",
    "    for col in range(columns):\n",
    "        if col + row * (rows + 1) < len(ys):\n",
    "            # create a bar for each metric defined above for a column of ys list\n",
    "            sns.barplot(data=df_data_analysis[df_data_analysis['metric'].isin(metrics)], x='metric', y=ys[col + row * (rows + 1)], ax=ax[row][col])\n",
    "            # set ylim to [0, 100] as we are plotting percentages\n",
    "            ax[row][col].set_ylim([0, 100])\n",
    "            # put the percentage above each plotted bar\n",
    "            ax[row][col].bar_label(ax[row][col].containers[0], fmt='%.1f')\n",
    "            # set the x, y and x-tick labels\n",
    "            ax[row][col].set_xlabel(\"\")\n",
    "            ax[row][col].set_ylabel(\"Share of values in %\")\n",
    "            ax[row][col].set_xticklabels(labels=[\"Missing values\", \"Zeros\"])\n",
    "            # use the column name with slight changes as subplot name\n",
    "            title = f\"{ys[col + row * (rows + 1)]}\".replace('_', ' ').replace('std', 'std. dev.').replace('2p5', '2.5').capitalize()\n",
    "            ax[row][col].set_title(title, fontsize = 15);\n",
    "        else:\n",
    "            # delete not needed subplots\n",
    "            fig.delaxes(ax[row][col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to plot\n",
    "ys = data_cols_wo_std\n",
    "\n",
    "# define size of subplot\n",
    "columns = 3\n",
    "rows = int(np.ceil((len(ys)) / columns))\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(rows, columns, figsize=(20,10)) # create subplots\n",
    "plt.suptitle(\"Outlier analysis\", fontsize=20) # title of plot\n",
    "fig.tight_layout() # tight_layout automatically adjusts subplot params so that the subplot(s) fits in to the figure area\n",
    "plt.subplots_adjust(hspace = .5, wspace = .2, top = .9) # adjusts the space between the single subplots\n",
    "\n",
    "for row in range(rows):\n",
    "    for col in range(columns):\n",
    "        if col + row * (rows + 1) < len(ys):\n",
    "            # create a bar for each metric defined above for a column of ys list\n",
    "            sns.scatterplot(data=df_sc, x='timestamp', y=ys[col + row * (rows + 1)], ax=ax[row][col], alpha=.3)\n",
    "            # set the x, y and x-tick labels\n",
    "            ax[row][col].set_xlabel(ax[row][col].get_xlabel().capitalize())\n",
    "            ax[row][col].set_ylabel(ax[row][col].get_ylabel().capitalize())\n",
    "            # use the column name with slight changes as subplot name\n",
    "            title = f\"{ys[col + row * (rows + 1)]}\".replace('_', ' ').replace('std', 'std. dev.').replace('2p5', '2.5').capitalize()\n",
    "            ax[row][col].set_title(title, fontsize = 15)\n",
    "            ax[row][col].tick_params(labelrotation=90)\n",
    "        else:\n",
    "            # delete not needed subplots\n",
    "            fig.delaxes(ax[row][col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are few outliers in humidity, pressure and temperature which can be dropped by setting thresholds. </br>\n",
    "For PM10 and PM2.5 it is less obvious as the data is scattered all over the possible range. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete unrealistic values and outliers for environmental variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hard thresholds based on physical estimations\n",
    "We can first have a look at the extreme values measured by Deutscher Wetterdienst to get an impression what range of values is realistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dwd['humidity'].max())\n",
    "print(df_dwd.query(\"City == 'Frankfurt'\")['humidity'].min())\n",
    "print(df_dwd.query(\"City == 'Bremen'\")['humidity'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dwd['pressure'].max())\n",
    "print(df_dwd.query(\"City == 'Frankfurt'\")['pressure'].min())\n",
    "print(df_dwd.query(\"City == 'Bremen'\")['pressure'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dwd['temperature'].max())\n",
    "print(df_dwd.query(\"City == 'Frankfurt'\")['temperature'].min())\n",
    "print(df_dwd.query(\"City == 'Bremen'\")['temperature'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholds_part = {\n",
    "#     'PM10': (0, 1000),\n",
    "#     'PM2p5': (0, 500),\n",
    "# }\n",
    "# set lower and upper threshold\n",
    "thresholds_env = {\n",
    "    'humidity': (15, 100),\n",
    "    'pressure': (960, 1050),\n",
    "    'temperature': (-20, 60),\n",
    "}\n",
    "\n",
    "# delete values below lower and above upper threshold\n",
    "for col, thresh in thresholds_env.items():\n",
    "    nan_before = df_sc[col].isna().sum()\n",
    "    df_sc.iloc[df_sc[col] <= thresh[0], list(df_sc.columns).index(col)] = np.nan\n",
    "    df_sc.iloc[df_sc[col] >= thresh[1], list(df_sc.columns).index(col)] = np.nan\n",
    "    print(f\"added {df_sc[col].isna().sum() - nan_before} nans in {col}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## values with std. dev. 'nan' or zero\n",
    "If the standard deviation is 'nan', there was no or only one observation. If the standard deviation is zero, there was no fluctuation in the measured value, what can be assumed to be a measurement error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete values for the defined columns if the standard deviation is zero or 'nan'\n",
    "for col in [\n",
    "    'temperature',\n",
    "    'humidity',\n",
    "    'pressure',\n",
    "]:\n",
    "    df_sc.loc[df_sc[col+'_std']==0, col] = np.nan    \n",
    "    df_sc.loc[df_sc[col+'_std']==np.nan, col] = np.nan    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dynamic thresholds based on quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define quantiles as threshold\n",
    "thresh = {\n",
    "    'temperature': (.01, .85),\n",
    "    'humidity': (.05, .95),\n",
    "    'pressure': (.05, .95),\n",
    "}\n",
    "\n",
    "# make a dataframe containing median, upper and lower threshold defined by the quantiles above\n",
    "df_thresholds = df_sc.groupby(['city', 'timestamp']).agg(\n",
    "    temp_median = pd.NamedAgg(column='temperature', aggfunc='median'), \n",
    "    temp_lower = pd.NamedAgg(column='temperature', aggfunc=lambda x: x.quantile(q=thresh['temperature'][0])),\n",
    "    temp_upper = pd.NamedAgg(column='temperature', aggfunc=lambda x: x.quantile(q=thresh['temperature'][1])),\n",
    "    hum_median = pd.NamedAgg(column='humidity', aggfunc='median'), \n",
    "    hum_lower = pd.NamedAgg(column='humidity', aggfunc=lambda x: x.quantile(q=thresh['humidity'][0])),\n",
    "    hum_upper = pd.NamedAgg(column='humidity', aggfunc=lambda x: x.quantile(q=thresh['humidity'][1])),\n",
    "    pres_median = pd.NamedAgg(column='pressure', aggfunc='median'), \n",
    "    pres_lower = pd.NamedAgg(column='pressure', aggfunc=lambda x: x.quantile(q=thresh['pressure'][0])),\n",
    "    pres_upper = pd.NamedAgg(column='pressure', aggfunc=lambda x: x.quantile(q=thresh['pressure'][1])),\n",
    ").reset_index()\n",
    "\n",
    "# merge the thresholds with the sc dataframe\n",
    "df_sc = df_sc.merge(df_thresholds, how='left', on=['city', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thresholds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace values below lower threshold and above upper threshold with 'nan'\n",
    "for col, thresholds in {\n",
    "    'temperature': ['temp_lower', 'temp_upper'],\n",
    "    'humidity': ['hum_lower', 'hum_upper'],\n",
    "    'pressure': ['pres_lower','pres_upper'],\n",
    "}.items():\n",
    "    nan_before = df_sc[col].isna().sum()\n",
    "    df_sc.loc[(df_sc[col] < df_sc[thresholds[0]]) | (df_sc[col] > df_sc[thresholds[1]]), col] = np.nan\n",
    "    print(f\"{df_sc[col].isna().sum() - nan_before} nans added in {col}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of cleaned data and comparison with dwd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dwd and sc data for Frankfurt\n",
    "# define columns to plot\n",
    "ys = data_cols_wo_std\n",
    "\n",
    "# define size of subplot\n",
    "columns = 1\n",
    "rows = int(np.ceil((len(ys)) / columns)) -1\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(rows, columns, figsize=(20,25)) # create subplots\n",
    "plt.suptitle(\"Comparison sensor data vs. dwd in Frankfurt\", fontsize=20) # title of plot\n",
    "fig.tight_layout() # tight_layout automatically adjusts subplot params so that the subplot(s) fits in to the figure area\n",
    "plt.subplots_adjust(hspace = .2, wspace = .2, top = .95) # adjusts the space between the single subplots\n",
    "\n",
    "# Plot humidity from both datasets vs time\n",
    "sns.scatterplot(data=df_sc[df_sc['city'] == 'Frankfurt'], x='timestamp', y='humidity', ax=ax[0])\n",
    "sns.lineplot(data=df_dwd[df_dwd['City']=='Frankfurt'], x='date', y='humidity', color='red', alpha=.5, ax=ax[0])\n",
    "ax[0].set_xlabel(ax[0].get_xlabel().capitalize())\n",
    "ax[0].set_ylabel(ax[0].get_ylabel().capitalize())\n",
    "\n",
    "# Plot humidity and precipitation from both datasets vs time\n",
    "sns.scatterplot(data=df_sc[df_sc['city'] == 'Frankfurt'], x='timestamp', y='humidity', ax=ax[1])\n",
    "sns.lineplot(data=df_dwd[df_dwd['City']=='Frankfurt'], x='date', y='precip', color='red', alpha=.5, ax=ax[1])\n",
    "ax[1].set_xlabel(ax[1].get_xlabel().capitalize())\n",
    "ax[1].set_ylabel(ax[1].get_ylabel().capitalize())\n",
    "\n",
    "# Plot pressure from both datasets vs time\n",
    "sns.scatterplot(data=df_sc[df_sc['city'] == 'Frankfurt'], x='timestamp', y='pressure', ax=ax[2])\n",
    "sns.lineplot(data=df_dwd[df_dwd['City']=='Frankfurt'], x='date', y='pressure', color='red', alpha=.5, ax=ax[2])\n",
    "ax[2].set_xlabel(ax[2].get_xlabel().capitalize())\n",
    "ax[2].set_ylabel(ax[2].get_ylabel().capitalize())\n",
    "\n",
    "# Plot temperature from both datasets vs time\n",
    "sns.scatterplot(data=df_sc[df_sc['city'] == 'Frankfurt'], x='timestamp', y='temperature', ax=ax[3])\n",
    "sns.lineplot(data=df_dwd[df_dwd['City']=='Frankfurt'], x='date', y='temperature', color='red', alpha=.5, ax=ax[3])\n",
    "ax[3].set_xlabel(ax[3].get_xlabel().capitalize())\n",
    "ax[3].set_ylabel(ax[3].get_ylabel().capitalize())\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dwd and sc data for Bremen\n",
    "# define columns to plot\n",
    "ys = data_cols_wo_std\n",
    "\n",
    "# define size of subplot\n",
    "columns = 1\n",
    "rows = int(np.ceil((len(ys)) / columns)) -1\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(rows, columns, figsize=(20,25)) # create subplots\n",
    "plt.suptitle(\"Comparison sensor data vs. dwd in Bremen\", fontsize=20) # title of plot\n",
    "fig.tight_layout() # tight_layout automatically adjusts subplot params so that the subplot(s) fits in to the figure area\n",
    "plt.subplots_adjust(hspace = .2, wspace = .2, top = .95) # adjusts the space between the single subplots\n",
    "\n",
    "# Plot humidity from both datasets vs time\n",
    "sns.scatterplot(data=df_sc[df_sc['city'] == 'Bremen'], x='timestamp', y='humidity', ax=ax[0])\n",
    "sns.lineplot(data=df_dwd[df_dwd['City']=='Bremen'], x='date', y='humidity', color='red', alpha=.5, ax=ax[0])\n",
    "ax[0].set_xlabel(ax[0].get_xlabel().capitalize())\n",
    "ax[0].set_ylabel(ax[0].get_ylabel().capitalize())\n",
    "\n",
    "# Plot humidity and precipitation \n",
    "sns.scatterplot(data=df_sc[df_sc['city'] == 'Bremen'], x='timestamp', y='humidity', ax=ax[1])\n",
    "sns.lineplot(data=df_dwd[df_dwd['City']=='Bremen'], x='date', y='precip', color='red', alpha=.5, ax=ax[1])\n",
    "ax[1].set_xlabel(ax[1].get_xlabel().capitalize())\n",
    "ax[1].set_ylabel(ax[1].get_ylabel().capitalize())\n",
    "\n",
    "# Plot pressure from both datasets vs time\n",
    "sns.scatterplot(data=df_sc[df_sc['city'] == 'Bremen'], x='timestamp', y='pressure', ax=ax[2])\n",
    "sns.lineplot(data=df_dwd[df_dwd['City']=='Bremen'], x='date', y='pressure', color='red', alpha=.5, ax=ax[2])\n",
    "ax[2].set_xlabel(ax[2].get_xlabel().capitalize())\n",
    "ax[2].set_ylabel(ax[2].get_ylabel().capitalize())\n",
    "\n",
    "# Plot temperature from both datasets vs time\n",
    "sns.scatterplot(data=df_sc[df_sc['city'] == 'Bremen'], x='timestamp', y='temperature', ax=ax[3])\n",
    "sns.lineplot(data=df_dwd[df_dwd['City']=='Bremen'], x='date', y='temperature', color='red', alpha=.5, ax=ax[3])\n",
    "ax[3].set_xlabel(ax[3].get_xlabel().capitalize())\n",
    "ax[3].set_ylabel(ax[3].get_ylabel().capitalize())\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the distribution of measured temperatures in one day\n",
    "sns.histplot(data=df_sc[(df_sc['timestamp']>'2020-07-01') & (df_sc['timestamp']<'2020-07-15')], x='temperature', bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigation of single locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by location_id and calculate the total number of hours with measurements, date of the first and of the last measurement\n",
    "location_grouped = df_sc[['location_id', 'hour', 'date']].\\\n",
    "    groupby(['location_id']).\\\n",
    "        agg(\n",
    "                hours = pd.NamedAgg(column='hour', aggfunc='count'), \n",
    "                date_min = pd.NamedAgg(column='date', aggfunc='min'),\n",
    "                date_max = pd.NamedAgg(column='date', aggfunc='max')\n",
    "            ).\\\n",
    "            reset_index().\\\n",
    "                sort_values('hours', ascending=False)\n",
    "\n",
    "location_grouped['date_min'] = pd.to_datetime(location_grouped['date_min'])\n",
    "location_grouped['date_max'] = pd.to_datetime(location_grouped['date_max'])\n",
    "location_grouped['period_length'] = location_grouped['date_max'] - location_grouped['date_min'] + pd.Timedelta(days=1)\n",
    "location_grouped['hours_per_day'] = location_grouped['hours'] / location_grouped['period_length'].dt.days\n",
    "location_grouped.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the number of hours that were measured at each location\n",
    "plt.figure(figsize=(25, 10))\n",
    "g = sns.barplot(data=location_grouped, x='location_id', y='hours', order=location_grouped.sort_values('hours', ascending=False)['location_id'])\n",
    "g.set_xlabel(g.get_xlabel().capitalize().replace('_', ' '))\n",
    "g.set_ylabel(g.get_ylabel().capitalize())\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the number of hours per day measured per location\n",
    "plt.figure(figsize=(25, 10))\n",
    "g = sns.barplot(data=location_grouped.sort_values('hours_per_day', ascending=False), x='location_id', y='hours_per_day', order=location_grouped.sort_values('hours_per_day', ascending=False)['location_id'])\n",
    "g.set_xlabel(g.get_xlabel().capitalize().replace('_', ' '))\n",
    "g.set_ylabel(g.get_ylabel().capitalize().replace('_', ' '))\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of locations: {location_grouped.shape[0]}\")\n",
    "print('Locations with the least hours of measurement:')\n",
    "location_grouped.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_grouped[['hours', 'hours_per_day']].describe().T.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some sensor locations which delivered data only for few hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(20, 20))\n",
    "plt.suptitle(\"Sensors per city\", fontsize=20) # title of plot\n",
    "fig.tight_layout() # tight_layout automatically adjusts subplot params so that the subplot(s) fits in to the figure area\n",
    "plt.subplots_adjust(hspace = .5, wspace = .2, top = .9) # adjusts the space between the single subplots\n",
    "\n",
    "labels_frankfurt = set(df_sc.query(\"city=='Frankfurt'\")['location_id'])\n",
    "labels_bremen = set(df_sc.query(\"city=='Bremen'\")['location_id'])\n",
    "\n",
    "sns.lineplot(data=df_sc[df_sc['city']=='Frankfurt'][::10], x='timestamp', y='PM10', hue='location_id', ax=ax1, legend=False)\n",
    "ax1.legend(labels=labels_frankfurt)\n",
    "ax1.set_title('Frankfurt - PM10', fontsize = 15)\n",
    "\n",
    "sns.lineplot(data=df_sc[df_sc['city']=='Frankfurt'][::10], x='timestamp', y='PM2p5', hue='location_id', ax=ax2, legend=False)\n",
    "ax2.legend(labels=labels_frankfurt)\n",
    "ax2.set_title('Frankfurt - PM2.5', fontsize = 15)\n",
    "\n",
    "sns.lineplot(data=df_sc[df_sc['city']=='Bremen'][::10], x='timestamp', y='PM10', hue='location_id', ax=ax3, legend=False)\n",
    "ax3.legend(labels=labels_bremen)\n",
    "ax3.set_title('Bremen - PM10', fontsize = 15)\n",
    "\n",
    "sns.lineplot(data=df_sc[df_sc['city']=='Bremen'][::10], x='timestamp', y='PM2p5', hue='location_id', ax=ax4, legend=False)\n",
    "ax4.legend(labels=labels_bremen)\n",
    "ax4.set_title('Bremen - PM2.5', fontsize = 15)\n",
    "#plt.legend([], [], frameon=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0eff187d94a6d345964e064b31a9e6fc453a64676d5a266be90b3132f78586ec"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
